{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "tensor([[[[-0.0862, -0.1932, -0.2216, -0.0873],\n",
      "          [-0.0502, -0.0715,  0.1485,  0.2203],\n",
      "          [ 0.0616,  0.1377,  0.0253,  0.0593],\n",
      "          [ 0.0039, -0.1559,  0.0376,  0.1531]]]])\n",
      "\n",
      "\n",
      "conv1.bias\n",
      "tensor([0.0109])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pprint\n",
    "\n",
    "\n",
    "#lets define a simple model\n",
    "class ConvNet(nn.Module):\n",
    "   \n",
    "    # Parameters:\n",
    "    #           inputDepth: This is the number of channels of the input image -- usually 3 for RGB\n",
    "    #           outputDepth: This is the number of channels coming out of the layer -- # of filters to apply\n",
    "    #           kernel_size: width / height of the kernal (filter)\n",
    "    \n",
    "    def __init__(self, inputDepth, outputDepth, kernal_size=4):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #A single convolutional layer\n",
    "        self.conv1 = nn.Conv2d(inputDepth, outputDepth, kernel_size=4, stride=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        return out\n",
    "\n",
    "#I am going to define a function to make experimenting easier\n",
    "def getInfo(inputDepth, outputDepth):\n",
    "    model = ConvNet(inputDepth, outputDepth)\n",
    "    sdict = model.state_dict()\n",
    "    modelLayers = [(layer, param) for (layer, param) in sdict.items()]\n",
    "    return modelLayers\n",
    "\n",
    "model_layers = getInfo(1,1)\n",
    "\n",
    "\n",
    "#lets take a look at what this looking like\n",
    "print(model_layers[0][0])\n",
    "print(model_layers[0][1])\n",
    "print('\\n') \n",
    "print(model_layers[1][0])\n",
    "print(model_layers[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This makes sense:\n",
    "\n",
    "    # layer are stored in         model_layers[0]:\n",
    "    #          layer name is in     model_layers[0][0]\n",
    "    #          layer weights are in model_layers[0][1]\n",
    "\n",
    "    # biases are store in the following layer in model_layers[1]:\n",
    "    #                         layer name is      model_layers[1][0]\n",
    "    #                         layer bias are in  model_layers[1][1]\n",
    "\n",
    "#Explanation of the weights:\n",
    "#These values are the values of the 4x4 filter or kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1244, -0.0269,  0.0086, -0.0200],\n",
      "          [-0.1702, -0.0098,  0.0286, -0.0900],\n",
      "          [-0.1577,  0.0061, -0.1146,  0.0653],\n",
      "          [-0.1009,  0.0391, -0.1539, -0.0539]],\n",
      "\n",
      "         [[ 0.1156,  0.0317,  0.1092, -0.0694],\n",
      "          [ 0.1506,  0.0758, -0.1158,  0.1255],\n",
      "          [-0.0117, -0.0984,  0.0354, -0.0052],\n",
      "          [-0.1521, -0.1415, -0.0400,  0.1448]]]])\n",
      "torch.Size([1, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lets see what happens when we introduce 2 input channels ---- \n",
    "# ---- from now on I am only going to print weights and ignore biases\n",
    "info = getInfo(2, 1)\n",
    "pprint.pprint(info[0][1])\n",
    "pprint.pprint(info[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now see there is a tensor of shape (1x2x4x4)\n",
    "#in words (i believe) the structure of the \n",
    "#tensor is: (output filters)x(input filters)x(height of kernal)x(width of kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1596, -0.1478, -0.1207,  0.0268],\n",
      "          [-0.0213,  0.1894, -0.1393,  0.1875],\n",
      "          [ 0.0165, -0.2045, -0.2181,  0.1380],\n",
      "          [ 0.1051,  0.2364,  0.0255,  0.1654]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1046, -0.0265,  0.1939,  0.1499],\n",
      "          [ 0.2461, -0.0630,  0.1849, -0.1932],\n",
      "          [-0.1160,  0.1278, -0.1098, -0.2062],\n",
      "          [ 0.1843,  0.1696, -0.0857,  0.1495]]]])\n",
      "torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Lets see what happens when we introduce 2 output channels ---- \n",
    "info = getInfo(1, 2)\n",
    "pprint.pprint(info[0][1])\n",
    "pprint.pprint(info[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1169,  0.1220,  0.0246, -0.0901],\n",
      "          [-0.0622,  0.0527, -0.1185,  0.0847],\n",
      "          [-0.0101, -0.1050,  0.0181, -0.0723],\n",
      "          [-0.0224, -0.0524,  0.1022,  0.1713]],\n",
      "\n",
      "         [[-0.0622, -0.1654, -0.0880, -0.1763],\n",
      "          [-0.0905, -0.0722, -0.0542,  0.1662],\n",
      "          [ 0.0811,  0.0021,  0.1104,  0.1484],\n",
      "          [ 0.0629,  0.0738, -0.0793,  0.1689]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1294,  0.1267,  0.0191, -0.0226],\n",
      "          [-0.0909, -0.1266, -0.0624, -0.0435],\n",
      "          [ 0.0287, -0.0448,  0.1242,  0.1441],\n",
      "          [ 0.0163, -0.0699, -0.1314, -0.1567]],\n",
      "\n",
      "         [[-0.1717,  0.0111,  0.0503, -0.1684],\n",
      "          [ 0.1632,  0.1122, -0.0684, -0.0699],\n",
      "          [-0.1750,  0.0308, -0.0904,  0.0080],\n",
      "          [ 0.1521,  0.0823, -0.0917, -0.0310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0527,  0.0909,  0.0840, -0.1324],\n",
      "          [ 0.1376,  0.0051, -0.0021, -0.0948],\n",
      "          [-0.0714, -0.0714,  0.1006,  0.1119],\n",
      "          [-0.0547, -0.0291,  0.0512, -0.1121]],\n",
      "\n",
      "         [[ 0.1603,  0.1098,  0.1322, -0.0480],\n",
      "          [-0.0188,  0.1007, -0.1027,  0.1356],\n",
      "          [ 0.0912,  0.0260, -0.1237,  0.1267],\n",
      "          [ 0.0885, -0.0790, -0.0770, -0.0908]]]])\n",
      "torch.Size([3, 2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#This is kind of expected ---- we can confirm the suspected tensor shape above\n",
    "\n",
    "\n",
    "#lets make this a little more complex and use 2 input channels and 3 input channels\n",
    "info = getInfo(2, 3)\n",
    "pprint.pprint(info[0][1])\n",
    "pprint.pprint(info[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0098,  0.0462, -0.0066,  0.1044],\n",
      "          [-0.0735,  0.0762,  0.0470,  0.0568],\n",
      "          [-0.1078,  0.1034,  0.0961,  0.0129],\n",
      "          [ 0.0859, -0.0339,  0.0137,  0.0295]],\n",
      "\n",
      "         [[-0.0111, -0.0906, -0.0843,  0.0029],\n",
      "          [-0.1166,  0.0847, -0.0159,  0.1203],\n",
      "          [-0.0726,  0.0424, -0.0769,  0.1095],\n",
      "          [-0.1405,  0.0398, -0.0763,  0.0761]],\n",
      "\n",
      "         [[ 0.0522, -0.1293,  0.1252,  0.1438],\n",
      "          [ 0.0320,  0.0665, -0.0361,  0.0286],\n",
      "          [-0.1219, -0.0670,  0.0782,  0.0159],\n",
      "          [-0.0659, -0.0394,  0.0817, -0.0587]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0994, -0.0189,  0.1107, -0.0459],\n",
      "          [ 0.1318, -0.0587,  0.0436,  0.0503],\n",
      "          [-0.1182,  0.0430,  0.0865, -0.0178],\n",
      "          [ 0.0689, -0.0560, -0.0021, -0.1428]],\n",
      "\n",
      "         [[-0.0263,  0.0476, -0.1092,  0.1204],\n",
      "          [ 0.0241,  0.1000,  0.1041,  0.0506],\n",
      "          [ 0.0044,  0.1185,  0.0891,  0.0244],\n",
      "          [ 0.0505,  0.0958,  0.0677, -0.1348]],\n",
      "\n",
      "         [[-0.0087,  0.0776,  0.0433,  0.0822],\n",
      "          [ 0.0891, -0.0025, -0.1202, -0.1079],\n",
      "          [ 0.0134,  0.0003,  0.0946,  0.0937],\n",
      "          [-0.1361, -0.0283, -0.1226, -0.0192]]]])\n",
      "torch.Size([2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Lets look at 3 input channels and 2 output channels\n",
    "info = getInfo(3, 2)\n",
    "pprint.pprint(info[0][1])\n",
    "pprint.pprint(info[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['conv1.', tensor([[[[ 0.0769, -0.0626, -0.0122, -0.0983],\n",
      "          [ 0.0488, -0.0306, -0.1050,  0.0276],\n",
      "          [ 0.0002,  0.1308,  0.0671,  0.1290],\n",
      "          [-0.0197,  0.1180, -0.0473,  0.0657]],\n",
      "\n",
      "         [[-0.0351, -0.0693,  0.1381, -0.0443],\n",
      "          [-0.0552, -0.0465, -0.0321,  0.0303],\n",
      "          [-0.0442, -0.1316,  0.0825,  0.1271],\n",
      "          [ 0.0985,  0.0699, -0.1259, -0.0003]],\n",
      "\n",
      "         [[ 0.0879, -0.0755,  0.1434, -0.0040],\n",
      "          [-0.1317, -0.0571, -0.0891, -0.1174],\n",
      "          [-0.0706, -0.0465, -0.0312,  0.1152],\n",
      "          [ 0.0118,  0.0015, -0.0644, -0.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0152, -0.0762,  0.0291,  0.0095],\n",
      "          [-0.0671,  0.0046, -0.0532, -0.0332],\n",
      "          [ 0.0426,  0.0453,  0.1406, -0.0818],\n",
      "          [-0.1021,  0.0786,  0.0267,  0.1312]],\n",
      "\n",
      "         [[ 0.1269,  0.0045,  0.1097, -0.1147],\n",
      "          [-0.1237, -0.1180, -0.0130, -0.0329],\n",
      "          [-0.0679, -0.1095, -0.0674,  0.1315],\n",
      "          [ 0.0558, -0.0090,  0.1173, -0.0903]],\n",
      "\n",
      "         [[-0.0484,  0.0812,  0.0212,  0.0400],\n",
      "          [ 0.0390,  0.1432,  0.0270,  0.0941],\n",
      "          [ 0.0764,  0.1299,  0.0546, -0.0974],\n",
      "          [ 0.0821,  0.1025, -0.0812,  0.1288]]]]), tensor([-0.0273, -0.0181])]]\n"
     ]
    }
   ],
   "source": [
    "#Great, with an understanding of how pytorch stores convolutional layers, lets try and iterate them\n",
    "from torchvision import models\n",
    "\n",
    "#I am going to redefine 'getInfo' function to collapse weights and biases for a layer together\n",
    "def getInfo(inputDepth, outputDepth):\n",
    "    #model = models.resnet101()\n",
    "    model = ConvNet(inputDepth, outputDepth)\n",
    "    sdict = model.state_dict()\n",
    "    modelLayers = [(layer, param) for (layer, param) in sdict.items()]\n",
    "    \n",
    "    weights = []\n",
    "    biases = []\n",
    "    for _layer in modelLayers:\n",
    "        if(not 'bn' in _layer[0] and not 'downsample' in _layer[0]):\n",
    "            if('weight' in _layer[0]):\n",
    "                weights.append((_layer[0][:-len('weight')], _layer[1]))\n",
    "            elif('bias' in _layer[0]):\n",
    "                biases.append((_layer[0][:-len('bias')], _layer[1]))\n",
    "  \n",
    "    cleanedLayers = []\n",
    "    for weight_name, weight in weights:\n",
    "        weight_nameFound = False\n",
    "        for bias_name, bias in biases:\n",
    "            if weight_name == bias_name:\n",
    "                cleanedLayers.append([weight_name, weight, bias])\n",
    "                weight_nameFound = True\n",
    "                break\n",
    "        if not weight_nameFound:\n",
    "            cleanedLayers.append([weight_name, weight, []])\n",
    "        \n",
    "    return cleanedLayers\n",
    "\n",
    "cleanedLayers = getInfo(3,2)\n",
    "print((cleanedLayers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['conv1.', tensor([[[[ 0.0514, -0.0300,  0.1021,  0.0090],\n",
      "          [-0.0535, -0.0181,  0.1166,  0.0969],\n",
      "          [-0.0288,  0.1353, -0.1340,  0.0002],\n",
      "          [ 0.0204,  0.0157,  0.0382,  0.0522]],\n",
      "\n",
      "         [[-0.1092, -0.0651,  0.0431, -0.0978],\n",
      "          [ 0.1304, -0.0445, -0.1115, -0.1316],\n",
      "          [ 0.0345,  0.1440, -0.0561, -0.1073],\n",
      "          [ 0.0772,  0.1240,  0.0377, -0.0599]],\n",
      "\n",
      "         [[ 0.0144,  0.1376, -0.0683,  0.1398],\n",
      "          [ 0.0178,  0.0206, -0.0785,  0.0086],\n",
      "          [ 0.1176, -0.0856,  0.0651,  0.0674],\n",
      "          [ 0.1386,  0.0525, -0.0703,  0.0331]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0926,  0.0537, -0.0306,  0.0959],\n",
      "          [ 0.0715, -0.0706, -0.0889, -0.0026],\n",
      "          [ 0.0720,  0.1013,  0.0181, -0.0535],\n",
      "          [ 0.0863,  0.1197, -0.0164, -0.1183]],\n",
      "\n",
      "         [[-0.0538, -0.0975,  0.0009,  0.1262],\n",
      "          [-0.1302,  0.0982, -0.0826, -0.0941],\n",
      "          [-0.1424,  0.1057, -0.0029, -0.0083],\n",
      "          [ 0.0988, -0.1165,  0.0983, -0.0516]],\n",
      "\n",
      "         [[-0.1285, -0.0342, -0.0470,  0.1396],\n",
      "          [ 0.0368, -0.0569,  0.1109, -0.0622],\n",
      "          [ 0.0111,  0.1246,  0.0770,  0.0392],\n",
      "          [-0.0409,  0.1002,  0.1320, -0.0989]]]]), tensor([ 0.0334, -0.0843])]]\n"
     ]
    }
   ],
   "source": [
    "#As we can see getInfo will now return a cleaned up version of the layers,weights, and biases\n",
    "#each index of 'cleanedLayers' is a particular layer\n",
    "#at each index 'i', \n",
    "#      cleanedLayers[i][0] is layer name, \n",
    "#      cleanedLayers[i][1] is weights, \n",
    "#      and cleanedLayers[i][2] is biases\n",
    "\n",
    "layers = getInfo(3,2)\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
